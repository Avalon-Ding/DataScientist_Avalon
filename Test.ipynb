{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "#from sklearn import linear_model as lm\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('Score_Pass.csv')\n",
    "X, y = np.array(data['Score']), np.array(data['Pass/N'])\n",
    "x=X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\theta_j=\\theta_j + \\alpha\\frac{1}{m}\\sum_{i=1}^m\\left[ y^{(i)}-h_\\theta\\left(x^{(i)}\\right)\\right]\\,x_j^{(i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, Θ_1, Θ_2):                                                        \n",
    "    z = (Θ_1*x + Θ_2).astype(\"float_\")                                              \n",
    "    return 1.0 / (1.0 + np.exp(-z)) \n",
    "\n",
    "\n",
    "def Cost(x, y, Θ_1, Θ_2):                                                                \n",
    "    sigmoid_probs = sigmoid(x, Θ_1, Θ_2)                                        \n",
    "    return np.sum(y * np.log(sigmoid_probs)\n",
    "                  + (1 - y) * np.log(1 - sigmoid_probs)) \n",
    "\n",
    "def gradient(x, y, Θ_1, Θ_2):                                                         \n",
    "    sigmoid_probs = sigmoid(x, Θ_1, Θ_2)                                        \n",
    "    return np.array([[np.sum((y - sigmoid_probs) * x),                          \n",
    "                     np.sum((y - sigmoid_probs) * 1)]])                         \n",
    "\n",
    "def hessian(x, y, Θ_1, Θ_2):                                                          \n",
    "    sigmoid_probs = sigmoid(x, Θ_1, Θ_2)                                        \n",
    "    d1 = np.sum((sigmoid_probs * (1 - sigmoid_probs)) * x * x)                  \n",
    "    d2 = np.sum((sigmoid_probs * (1 - sigmoid_probs)) * x * 1)                  \n",
    "    d3 = np.sum((sigmoid_probs * (1 - sigmoid_probs)) * 1 * 1)                  \n",
    "    H = np.array([[d1, d2],[d2, d3]])                                           \n",
    "    return H\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GradDe(X,y,Max_Loop=20, alpha=0.00001):\n",
    "    #alpha = 0.00000001\n",
    "    #Max_Loop = 200\n",
    "    Θ_1 = 0.0001\n",
    "    Θ_2 = -0.04\n",
    "    \n",
    "    for l in range(Max_Loop):\n",
    "        Θ_1 = Θ_1 + alpha * np.sum((y-sigmoid(X, Θ_1, Θ_2)) * X)\n",
    "        Θ_2 = Θ_2 + alpha * np.sum(y-sigmoid(X, Θ_1, Θ_2))\n",
    "        \n",
    "        print(Cost(X, y, Θ_1, Θ_2), gradient(X,y,Θ_1, Θ_2))\n",
    "        \n",
    "    print([Θ_1, Θ_2])\n",
    "    return [Θ_1, Θ_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-503.725836684 [[-964.73121299  -75.47359542]]\n",
      "-503.719835005 [[-267.92804485  -74.39704665]]\n",
      "-503.71932146 [[-74.34971992 -74.09796698]]\n",
      "-503.71923136 [[-20.57238286 -74.01487521]]\n",
      "-503.719173908 [[ -5.63262743 -73.99178614]]\n",
      "-503.719118966 [[ -1.48224279 -73.98536628]]\n",
      "-503.719064217 [[ -0.32923191 -73.98357725]]\n",
      "-503.719009481 [[ -8.91599379e-03  -7.39830747e+01]]\n",
      "-503.718954746 [[  0.0800704  -73.98292956]]\n",
      "-503.718900011 [[  0.10479155 -73.9828837 ]]\n",
      "-503.718845276 [[  0.11165928 -73.98286542]]\n",
      "-503.718790541 [[  0.11356718 -73.98285481]]\n",
      "-503.718735806 [[  0.1140972  -73.98284632]]\n",
      "-503.718681072 [[  0.11424444 -73.98283843]]\n",
      "-503.718626337 [[  0.11428533 -73.9828307 ]]\n",
      "-503.718571602 [[  0.11429669 -73.98282301]]\n",
      "-503.718516867 [[  0.11429983 -73.98281534]]\n",
      "-503.718462132 [[  0.1143007  -73.98280767]]\n",
      "-503.718407398 [[  0.11430093 -73.98280001]]\n",
      "-503.718352663 [[  0.11430098 -73.98279234]]\n",
      "[5.1940616299646171e-05, -0.040014817240837067]\n"
     ]
    }
   ],
   "source": [
    "weights = GradDe(X,y,20,0.00000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "5.1940616299646171e-05, -0.040014817240837067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newtons_method(x, y):                                                             \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize Cost & parameters                                                                   \n",
    "    Θ_1 = 0.001                                                                     \n",
    "    Θ_2 = -0.4 # The intercept term                                                                 \n",
    "    delta_l = np.Infinity                                                                \n",
    "    l = Cost(x, y, Θ_1, Θ_2)                                                                 \n",
    "    # Convergence Conditions                                                        \n",
    "    δ = .0000000001                                                                 \n",
    "    max_iterations = 15                                                            \n",
    "    i = 0                                                                           \n",
    "    while abs(delta_l) > δ and i < max_iterations:                                       \n",
    "        i += 1                                                                      \n",
    "        g = gradient(x, y, Θ_1, Θ_2)                                                      \n",
    "        hess = hessian(x, y, Θ_1, Θ_2)                                                 \n",
    "        H_inv = np.linalg.inv(hess)                                                 \n",
    "        # @ is syntactic sugar for np.dot(H_inv, g.T)¹\n",
    "        delta = H_inv @ g.T                                                             \n",
    "        delta_Θ_1 = delta[0][0]                                                              \n",
    "        delta_Θ_2 = delta[1][0]  \n",
    "        print(Θ_1,Θ_2,l,g)\n",
    "                                                                                    \n",
    "        # Perform our update step                                                    \n",
    "        Θ_1 += delta_Θ_1                                                                 \n",
    "        Θ_2 += delta_Θ_2                                                                 \n",
    "                                                                                    \n",
    "        # Update the log-likelihood at each iteration                                     \n",
    "        l_new = Cost(x, y, Θ_1, Θ_2)                                                      \n",
    "        delta_l = l - l_new                                                           \n",
    "        l = l_new                                                                \n",
    "    return np.array([Θ_1, Θ_2])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 -0.4 -483.268693545 [[-28024.3244961   -113.6228469]]\n",
      "0.0112576600667 -7.27041636976 -194.098783032 [[-4751.72666163   -27.94893012]]\n",
      "0.0196272786295 -12.7884192394 -120.225925481 [[-1303.99280455   -10.2602213 ]]\n",
      "0.0297371807762 -19.4082678025 -84.7723651278 [[ 224.55427607   -2.97851801]]\n",
      "0.0418724485742 -27.2808836967 -68.057215957 [[ 460.36914031   -0.54775886]]\n",
      "0.0542514160377 -35.2634488806 -61.882910202 [[  2.75407730e+02   3.10212067e-02]]\n",
      "0.0626937102006 -40.6883474956 -60.6575636785 [[  8.31196135e+01   5.16989581e-02]]\n",
      "0.0652583036832 -42.3325318804 -60.5908898311 [[  6.74827902e+00   5.85997656e-03]]\n",
      "0.0654319147359 -42.4436576359 -60.5906289243 [[  3.39533720e-02   3.37330329e-05]]\n",
      "0.0654326355822 -42.4441184864 -60.5906289199 [[  6.64767924e-07   7.06533165e-10]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0.06543264, -42.44411849])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtons_method(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
