{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "#from sklearn import linear_model as lm\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('Score_Pass.csv')\n",
    "X, y = np.array(data['Score']), np.array(data['Pass/N'])\n",
    "x=X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\theta_j=\\theta_j + \\alpha\\frac{1}{m}\\sum_{i=1}^m\\left[ y^{(i)}-h_\\theta\\left(x^{(i)}\\right)\\right]\\,x_j^{(i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, Θ_1, Θ_2):                                                        \n",
    "    z = (Θ_1*x + Θ_2).astype(\"float_\")                                              \n",
    "    return 1.0 / (1.0 + np.exp(-z)) \n",
    "\n",
    "\n",
    "def Cost(x, y, Θ_1, Θ_2):                                                                \n",
    "    sigmoid_probs = sigmoid(x, Θ_1, Θ_2)                                        \n",
    "    return np.sum(y * np.log(sigmoid_probs)\n",
    "                  + (1 - y) * np.log(1 - sigmoid_probs)) \n",
    "\n",
    "def gradient(x, y, Θ_1, Θ_2):                                                         \n",
    "    sigmoid_probs = sigmoid(x, Θ_1, Θ_2)                                        \n",
    "    return np.array([[np.sum((y - sigmoid_probs) * x),                          \n",
    "                     np.sum((y - sigmoid_probs) * 1)]])                         \n",
    "\n",
    "def hessian(x, y, Θ_1, Θ_2):                                                          \n",
    "    sigmoid_probs = sigmoid(x, Θ_1, Θ_2)                                        \n",
    "    d1 = np.sum((sigmoid_probs * (1 - sigmoid_probs)) * x * x)                  \n",
    "    d2 = np.sum((sigmoid_probs * (1 - sigmoid_probs)) * x * 1)                  \n",
    "    d3 = np.sum((sigmoid_probs * (1 - sigmoid_probs)) * 1 * 1)                  \n",
    "    H = np.array([[d1, d2],[d2, d3]])                                           \n",
    "    return H\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GradDe(X,y,Max_Loop=20, alpha=0.00001):\n",
    "    #alpha = 0.00000001\n",
    "    #Max_Loop = 200\n",
    "    Θ_1 = 0.0001\n",
    "    Θ_2 = -0.04\n",
    "    \n",
    "    for l in range(Max_Loop):\n",
    "        Θ_1 = Θ_1 + alpha * np.sum((y-sigmoid(X, Θ_1, Θ_2)) * X)\n",
    "        Θ_2 = Θ_2 + alpha * np.sum(y-sigmoid(X, Θ_1, Θ_2))\n",
    "        \n",
    "        print(Cost(X, y, Θ_1, Θ_2), gradient(X,y,Θ_1, Θ_2))\n",
    "        \n",
    "    print([Θ_1, Θ_2])\n",
    "    return [Θ_1, Θ_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6127.31734672 [[ 222442.99150504     289.99739228]]\n",
      "nan [[-223871.    -441.]]\n",
      "-6445.01195409 [[ 222443.42162531     289.99849698]]\n",
      "nan [[-223871.    -441.]]\n",
      "-6762.61135399 [[ 222443.66721671     289.9991313 ]]\n",
      "nan [[-223871.    -441.]]\n",
      "-7080.15639238 [[ 222443.8079761     289.9994967]]\n",
      "nan [[-223871.    -441.]]\n",
      "-7397.67027396 [[ 222443.88891637     289.99970777]]\n",
      "nan [[-223871.    -441.]]\n",
      "-7715.16623968 [[ 222443.93559343     289.99982999]]\n",
      "nan [[-223871.    -441.]]\n",
      "-8032.65187363 [[ 222443.96258043     289.99990092]]\n",
      "nan [[-223871.    -441.]]\n",
      "-8350.13153416 [[ 222443.97821923     289.99994216]]\n",
      "nan [[-223871.    -441.]]\n",
      "-8667.60773315 [[ 222443.98730061     289.99996619]]\n",
      "nan [[-223871.    -441.]]\n",
      "-8985.08192204 [[ 222443.99258407     289.99998021]]\n",
      "nan [[-223871.    -441.]]\n",
      "[0.18257430902118316, -0.40151000615371946]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiaoli Chen\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Xiaoli Chen\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:9: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "weights = GradDe(X,y,20,0.00000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newtons_method(x, y):                                                             \n",
    "    \"\"\"\n",
    "    :param x (np.array(float)): Vector of Boston House Values in dollars\n",
    "    :param y (np.array(boolean)): Vector of Bools indicting if house has > 2 bedrooms:\n",
    "    :returns: np.array of logreg's parameters after convergence, [Θ_1, Θ_2]\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize Cost & parameters                                                                   \n",
    "    Θ_1 = 0.001                                                                     \n",
    "    Θ_2 = -0.4 # The intercept term                                                                 \n",
    "    delta_l = np.Infinity                                                                \n",
    "    l = Cost(x, y, Θ_1, Θ_2)                                                                 \n",
    "    # Convergence Conditions                                                        \n",
    "    δ = .0000000001                                                                 \n",
    "    max_iterations = 15                                                            \n",
    "    i = 0                                                                           \n",
    "    while abs(delta_l) > δ and i < max_iterations:                                       \n",
    "        i += 1                                                                      \n",
    "        g = gradient(x, y, Θ_1, Θ_2)                                                      \n",
    "        hess = hessian(x, y, Θ_1, Θ_2)                                                 \n",
    "        H_inv = np.linalg.inv(hess)                                                 \n",
    "        # @ is syntactic sugar for np.dot(H_inv, g.T)¹\n",
    "        delta = H_inv @ g.T                                                             \n",
    "        delta_Θ_1 = delta[0][0]                                                              \n",
    "        delta_Θ_2 = delta[1][0]  \n",
    "        #print(Θ_1,Θ_2,delta_Θ_2,g)\n",
    "                                                                                    \n",
    "        # Perform our update step                                                    \n",
    "        Θ_1 += delta_Θ_1                                                                 \n",
    "        Θ_2 += delta_Θ_2                                                                 \n",
    "                                                                                    \n",
    "        # Update the log-likelihood at each iteration                                     \n",
    "        l_new = Cost(x, y, Θ_1, Θ_2)                                                      \n",
    "        delta_l = l - l_new                                                           \n",
    "        l = l_new                                                                \n",
    "    return np.array([Θ_1, Θ_2])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newtons_method(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
